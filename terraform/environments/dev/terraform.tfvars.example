# ================================================
# ğŸ“ Learning Configuration File
# ================================================
# terraform/environments/dev/terraform.tfvars.example
# Copy this to terraform.tfvars and customize for your learning!

# ================================================
# ğŸ·ï¸ Your Project Identity
# ================================================
project_name = "learning-lakehouse"   # Max 20 characters, lowercase with hyphens
environment  = "dev"                  # Keep as 'dev' for learning
aws_region   = "us-east-1"           # Try different regions if you want!

# ================================================
# ğŸ›ï¸ AWS Services Learning Lab
# ================================================
# Toggle individual AWS services to learn what each one does!

aws_services = {
  enable_eventbridge   = true   # ğŸ”„ Event-driven magic - try false to break automation!
  enable_sns          = true   # ğŸ“§ Email alerts - disable to go silent
  enable_cloudwatch   = true   # ğŸ“Š Basic monitoring - keep this on
  enable_grafana      = false  # ğŸ“ˆ Pretty dashboards - costs $20/month extra
  enable_rds          = false  # ğŸ—„ï¸  Database - costs $15/month extra  
  enable_chaos_testing = false # ğŸ§ª Advanced resilience testing (multiple services)
}

# ================================================
# ğŸš€ Quick Learning Presets
# ================================================
# Choose ONE of these for instant configuration:

learning_preset = "basic"          # ğŸ’° Cheapest - core features only (~$10/month)
# learning_preset = "intermediate"   # ğŸ“Š Balanced - adds monitoring (~$30/month)
# learning_preset = "advanced"       # ğŸ”¥ Full features - more expensive (~$60/month)
# learning_preset = "enterprise"     # ğŸ¢ Production-ready - most expensive (~$100/month)
# learning_preset = "cost-optimized" # ğŸ’¸ Absolute minimum cost (~$5/month)

# ================================================
# ğŸ¯ Your Contact Information
# ================================================
self_healing_config = {
  notification_email      = "your-email@gmail.com"  # ğŸ“§ CHANGE THIS TO YOUR EMAIL!
  enable_auto_remediation = true                     # Let the system fix itself
  alert_thresholds = {
    data_quality_failures = 3    # Send alert after 3 consecutive failures
    storage_threshold_gb   = 100  # Alert when storage exceeds 100GB
    error_rate_percent     = 5    # Alert when error rate exceeds 5%
  }
}

# ================================================
# ğŸ—ï¸ Advanced Customization (Optional)
# ================================================
# Only change these if you want to experiment with specific settings!

# Data Processing Performance Tuning
processing_config = {
  enable_crawler      = true
  enable_data_quality = true
  enable_remediation  = true
  glue_version       = "4.0"
  worker_type        = "G.1X"    # ğŸ’¡ Try: "G.1X" (cheap), "G.2X" (fast), "Standard" (balanced)
  number_of_workers  = 2         # ğŸ’¡ Try: 2 (small), 5 (medium), 10 (large datasets)
  schedule_crawler   = "cron(0 6,12,18 ? * MON-FRI *)"  # Run 3x daily on weekdays
  schedule_quality   = "cron(0 2,8,14,20 * * ? *)"      # Run 4x daily
}

# Network Configuration
networking_config = {
  vpc_cidr           = "10.0.0.0/16"
  enable_nat_gateway = false  # ğŸ’° false = cheaper, true = more secure but costs extra
  enable_flow_logs   = true   # Good for learning about network traffic
  availability_zones = 2      # Multi-AZ for reliability
}

# Storage Configuration  
data_lake_config = {
  enable_versioning = true
  enable_lifecycle  = true   # Automatically move old data to cheaper storage
  enable_encryption = true   # Always encrypt your data!
  storage_classes   = ["STANDARD", "STANDARD_IA", "GLACIER"]
}

# Monitoring Configuration
observability_config = {
  enable_prometheus         = false  # ğŸ’° Keep false in dev to save costs
  enable_grafana           = true    # Pretty dashboards for learning
  enable_enhanced_monitoring = true
  dashboard_types          = ["main", "detailed"]  # Try adding "cost", "security"
  retention_days           = 7       # How long to keep logs
}

# Database Settings (only used if enable_rds = true above)
rds_config = {
  instance_class    = "db.t3.micro"  # ğŸ’° Smallest size for learning
  allocated_storage = 20             # GB of storage
  engine_version    = "15.7"         # PostgreSQL version
  multi_az         = false           # ğŸ’° Single AZ saves money in dev
  backup_retention = 7               # Days to keep database backups
}

# ================================================
# ğŸ’¡ Learning Tips & Next Steps
# ================================================
# 
# 1. ğŸš€ Start here: Deploy with current settings using `make apply`
# 2. ğŸ“Š Upload data: aws s3 cp your-file.csv s3://YOUR-BUCKET-NAME/raw/
# 3. ğŸ” Watch magic: Check AWS Console for automatic processing
# 4. ğŸ§ª Experiment: Change feature toggles and redeploy
# 5. ğŸ“ˆ Scale up: Try different worker types and sizes
# 6. ğŸ’° Monitor costs: Check AWS Cost Explorer regularly
# 7. ğŸ§¹ Clean up: Run `make clean` when done learning
#
# Remember: Every change you make here teaches you about infrastructure!
# Don't be afraid to experiment - that's how you learn! ğŸ“