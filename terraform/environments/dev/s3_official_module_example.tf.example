# ============================================
# [CODE PILLAR] S3 Bucket using Official Module
# ============================================
# Purpose: Example of using terraform-aws-modules for cleaner, more maintainable code
# Benefit: Reduces custom code, leverages community best practices
# Three Pillars Role: Same functionality with less maintenance overhead
# 
# To use this instead of custom s3.tf:
# 1. Rename s3.tf to s3.tf.backup
# 2. Rename this file to s3_official_module.tf
# 3. Run terraform init to download the module

module "data_lake_bucket" {
  source = "terraform-aws-modules/s3-bucket/aws"
  version = "~> 4.0"

  bucket = "self-healing-lakehouse-${random_id.suffix.hex}"

  # Code Pillar: Consistent versioning
  versioning = {
    enabled = true
  }

  # Code Pillar: Automated lifecycle management
  lifecycle_rule = [
    {
      id     = "data_lifecycle"
      status = "Enabled"
      
      transition = [
        {
          days          = 30
          storage_class = "STANDARD_IA"
        },
        {
          days          = 90
          storage_class = "GLACIER"
        }
      ]
    }
  ]

  # Observability Pillar: Enable logging
  logging = {
    target_bucket = module.access_logs_bucket.s3_bucket_id
    target_prefix = "data-lake-access-logs/"
  }

  tags = {
    Pillar    = "Code"
    Purpose   = "Data lake using official module"
    Component = "Storage"
  }
}

module "access_logs_bucket" {
  source = "terraform-aws-modules/s3-bucket/aws"
  version = "~> 4.0"

  bucket = "self-healing-lakehouse-logs-${random_id.suffix.hex}"

  # Restrict access to access logs only
  attach_elb_log_delivery_policy = false
  attach_lb_log_delivery_policy  = false
  
  tags = {
    Pillar    = "Observability"
    Purpose   = "Access logging"
    Component = "Logging"
  }
}
